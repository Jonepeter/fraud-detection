{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building and Training for Fraud Detection\n",
    "\n",
    "This notebook builds and trains models for fraud detection using the preprocessed datasets:\n",
    "1. Fraud_Data.csv - E-commerce transaction data\n",
    "2. creditcard.csv - Bank transaction data\n",
    "\n",
    "We will build and compare two models for each dataset:\n",
    "1. Logistic Regression - As a simple, interpretable baseline\n",
    "2. XGBoost - As a powerful ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Add the src directory to the path\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "# Import custom modules\n",
    "from model import (\n",
    "    train_logistic_regression, train_xgboost, evaluate_model,\n",
    "    plot_confusion_matrix, plot_roc_curve, plot_precision_recall_curve,\n",
    "    save_model\n",
    ")\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "\n",
    "# Display all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load Fraud_Data splits\n",
    "X_train_fraud = joblib.load('../data/processed/X_train_fraud.pkl')\n",
    "X_test_fraud = joblib.load('../data/processed/X_test_fraud.pkl')\n",
    "y_train_fraud = joblib.load('../data/processed/y_train_fraud.pkl')\n",
    "y_test_fraud = joblib.load('../data/processed/y_test_fraud.pkl')\n",
    "X_train_fraud_resampled = joblib.load('../data/processed/X_train_fraud_resampled.pkl')\n",
    "y_train_fraud_resampled = joblib.load('../data/processed/y_train_fraud_resampled.pkl')\n",
    "\n",
    "# Load Creditcard splits\n",
    "X_train_cc = joblib.load('../data/processed/X_train_cc.pkl')\n",
    "X_test_cc = joblib.load('../data/processed/X_test_cc.pkl')\n",
    "y_train_cc = joblib.load('../data/processed/y_train_cc.pkl')\n",
    "y_test_cc = joblib.load('../data/processed/y_test_cc.pkl')\n",
    "X_train_cc_resampled = joblib.load('../data/processed/X_train_cc_resampled.pkl')\n",
    "y_train_cc_resampled = joblib.load('../data/processed/y_train_cc_resampled.pkl')\n",
    "\n",
    "# Print shapes\n",
    "print(f\"Fraud_Data: X_train shape = {X_train_fraud.shape}, X_test shape = {X_test_fraud.shape}\")\n",
    "print(f\"Fraud_Data (resampled): X_train shape = {X_train_fraud_resampled.shape}\")\n",
    "print(f\"Creditcard: X_train shape = {X_train_cc.shape}, X_test shape = {X_test_cc.shape}\")\n",
    "print(f\"Creditcard (resampled): X_train shape = {X_train_cc_resampled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train Models for Fraud_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train Logistic Regression model\n",
    "lr_fraud = train_logistic_regression(X_train_fraud_resampled, y_train_fraud_resampled)\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_fraud = train_xgboost(X_train_fraud_resampled, y_train_fraud_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate Logistic Regression model\n",
    "lr_fraud_metrics = evaluate_model(lr_fraud, X_test_fraud, y_test_fraud)\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "for metric, value in lr_fraud_metrics.items():\n",
    "    if metric != 'confusion_matrix':\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(lr_fraud_metrics['confusion_matrix'], 'Logistic Regression (Fraud_Data)')\n",
    "\n",
    "# Plot ROC curve\n",
    "plot_roc_curve(y_test_fraud, lr_fraud.predict_proba(X_test_fraud)[:, 1], 'Logistic Regression (Fraud_Data)')\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "plot_precision_recall_curve(y_test_fraud, lr_fraud.predict_proba(X_test_fraud)[:, 1], 'Logistic Regression (Fraud_Data)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate XGBoost model\n",
    "xgb_fraud_metrics = evaluate_model(xgb_fraud, X_test_fraud, y_test_fraud)\n",
    "print(\"XGBoost Metrics:\")\n",
    "for metric, value in xgb_fraud_metrics.items():\n",
    "    if metric != 'confusion_matrix':\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(xgb_fraud_metrics['confusion_matrix'], 'XGBoost (Fraud_Data)')\n",
    "\n",
    "# Plot ROC curve\n",
    "plot_roc_curve(y_test_fraud, xgb_fraud.predict_proba(X_test_fraud)[:, 1], 'XGBoost (Fraud_Data)')\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "plot_precision_recall_curve(y_test_fraud, xgb_fraud.predict_proba(X_test_fraud)[:, 1], 'XGBoost (Fraud_Data)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare models for Fraud_Data\n",
    "fraud_metrics = pd.DataFrame({\n",
    "    'Logistic Regression': {\n",
    "        'Accuracy': lr_fraud_metrics['accuracy'],\n",
    "        'Precision': lr_fraud_metrics['precision'],\n",
    "        'Recall': lr_fraud_metrics['recall'],\n",
    "        'F1 Score': lr_fraud_metrics['f1_score'],\n",
    "        'ROC AUC': lr_fraud_metrics['roc_auc'],\n",
    "        'PR AUC': lr_fraud_metrics['pr_auc']\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'Accuracy': xgb_fraud_metrics['accuracy'],\n",
    "        'Precision': xgb_fraud_metrics['precision'],\n",
    "        'Recall': xgb_fraud_metrics['recall'],\n",
    "        'F1 Score': xgb_fraud_metrics['f1_score'],\n",
    "        'ROC AUC': xgb_fraud_metrics['roc_auc'],\n",
    "        'PR AUC': xgb_fraud_metrics['pr_auc']\n",
    "    }\n",
    "})\n",
    "\n",
    "fraud_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save the models\n",
    "save_model(lr_fraud, 'lr_fraud')\n",
    "save_model(xgb_fraud, 'xgb_fraud')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Models for Creditcard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train Logistic Regression model\n",
    "lr_cc = train_logistic_regression(X_train_cc_resampled, y_train_cc_resampled)\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_cc = train_xgboost(X_train_cc_resampled, y_train_cc_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate Logistic Regression model\n",
    "lr_cc_metrics = evaluate_model(lr_cc, X_test_cc, y_test_cc)\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "for metric, value in lr_cc_metrics.items():\n",
    "    if metric != 'confusion_matrix':\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(lr_cc_metrics['confusion_matrix'], 'Logistic Regression (Creditcard)')\n",
    "\n",
    "# Plot ROC curve\n",
    "plot_roc_curve(y_test_cc, lr_cc.predict_proba(X_test_cc)[:, 1], 'Logistic Regression (Creditcard)')\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "plot_precision_recall_curve(y_test_cc, lr_cc.predict_proba(X_test_cc)[:, 1], 'Logistic Regression (Creditcard)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate XGBoost model\n",
    "xgb_cc_metrics = evaluate_model(xgb_cc, X_test_cc, y_test_cc)\n",
    "print(\"XGBoost Metrics:\")\n",
    "for metric, value in xgb_cc_metrics.items():\n",
    "    if metric != 'confusion_matrix':\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(xgb_cc_metrics['confusion_matrix'], 'XGBoost (Creditcard)')\n",
    "\n",
    "# Plot ROC curve\n",
    "plot_roc_curve(y_test_cc, xgb_cc.predict_proba(X_test_cc)[:, 1], 'XGBoost (Creditcard)')\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "plot_precision_recall_curve(y_test_cc, xgb_cc.predict_proba(X_test_cc)[:, 1], 'XGBoost (Creditcard)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare models for Creditcard\n",
    "cc_metrics = pd.DataFrame({\n",
    "    'Logistic Regression': {\n",
    "        'Accuracy': lr_cc_metrics['accuracy'],\n",
    "        'Precision': lr_cc_metrics['precision'],\n",
    "        'Recall': lr_cc_metrics['recall'],\n",
    "        'F1 Score': lr_cc_metrics['f1_score'],\n",
    "        'ROC AUC': lr_cc_metrics['roc_auc'],\n",
    "        'PR AUC': lr_cc_metrics['pr_auc']\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'Accuracy': xgb_cc_metrics['accuracy'],\n",
    "        'Precision': xgb_cc_metrics['precision'],\n",
    "        'Recall': xgb_cc_metrics['recall'],\n",
    "        'F1 Score': xgb_cc_metrics['f1_score'],\n",
    "        'ROC AUC': xgb_cc_metrics['roc_auc'],\n",
    "        'PR AUC': xgb_cc_metrics['pr_auc']\n",
    "    }\n",
    "})\n",
    "\n",
    "cc_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save the models\n",
    "save_model(lr_cc, 'lr_cc')\n",
    "save_model(xgb_cc, 'xgb_cc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Selection and Justification\n",
    "\n",
    "### Fraud_Data\n",
    "\n",
    "[After running the notebook, analyze the results and provide justification for the best model here]\n",
    "\n",
    "### Creditcard\n",
    "\n",
    "[After running the notebook, analyze the results and provide justification for the best model here]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}